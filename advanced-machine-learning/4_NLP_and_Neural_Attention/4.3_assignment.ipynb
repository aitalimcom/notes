{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“ Unit 4 Assignment: NLP & Transformers\n",
                "\n",
                "**Objective:** Practice text preprocessing, understanding embeddings, and using pre-trained Transformer models.\n",
                "\n",
                "**Instructions:**\n",
                "1.  Complete the tasks in each section.\n",
                "2.  Install necessary libraries if missing: `!pip install nltk transformers torch`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Conceptual Questions\n",
                "\n",
                "**1. Why is One-Hot Encoding inefficient for large vocabularies?**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> *Write your answer here.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2. In the sentence \"The bank of the river\", how does Self-Attention help the model understand the word \"bank\"?**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> *Write your answer here.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Preprocessing Pipeline\n",
                "\n",
                "**Task 2.1:** Write a function `clean_text(text)` that:\n",
                "1.  Converts text to lowercase.\n",
                "2.  Tokenizes it.\n",
                "3.  Removes stopwords.\n",
                "4.  Lemmatizes tokens.\n",
                "\n",
                "Use the sample text provided."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "\n",
                "nltk.download('punkt')\n",
                "nltk.download('stopwords')\n",
                "nltk.download('wordnet')\n",
                "\n",
                "sample_text = \"Deep Learning is driving the revolution in Artificial Intelligence!\"\n",
                "\n",
                "def clean_text(text):\n",
                "    # Your Code Here\n",
                "    return []\n",
                "\n",
                "print(clean_text(sample_text))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Text Classification with Embeddings\n",
                "\n",
                "**Task 3.1:** Use PyTorch to build a simple Sentiment Classifier consisting of:\n",
                "1.  `Embedding` Layer.\n",
                "2.  Aggregation (mean pooling or flatten).\n",
                "3.  `Linear` Output Layer.\n",
                "\n",
                "Train it on the dummy data provided."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Dummy Data\n",
                "reviews = [\n",
                "    'nice food',\n",
                "    'amazing restaurant',\n",
                "    'too good',\n",
                "    'just loved it',\n",
                "    'will go again',\n",
                "    'horrible food',\n",
                "    'never go there',\n",
                "    'poor service',\n",
                "    'poor quality',\n",
                "    'bad taste'\n",
                "]\n",
                "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])  # 1=Pos, 0=Neg\n",
                "\n",
                "vocab_size = 50\n",
                "max_len = 4\n",
                "\n",
                "# 1. Simple tokenization (Your implementation)\n",
                "# Create word_to_idx dictionary and convert reviews to sequences\n",
                "# Your Code Here\n",
                "\n",
                "# 2. Pad Sequences\n",
                "# Your Code Here\n",
                "\n",
                "# 3. Define Model\n",
                "class SentimentClassifier(nn.Module):\n",
                "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
                "        super(SentimentClassifier, self).__init__()\n",
                "        # Your Code Here\n",
                "        pass\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Your Code Here\n",
                "        pass\n",
                "\n",
                "# 4. Train\n",
                "# model = SentimentClassifier(...)\n",
                "# criterion = nn.CrossEntropyLoss()\n",
                "# optimizer = optim.Adam(model.parameters())\n",
                "# Your training loop here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Using Transformers\n",
                "\n",
                "**Task 4.1:** Load a pre-trained sentiment analysis pipeline from Hugging Face and test it on 3 custom sentences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Your Code Here"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}