{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.1 Probability Distributions\\n\n",
        "\\n\n",
        "**Syllabus Topic:** 1.1 Probability Distributions\\n\n",
        "\\n\n",
        "## Introduction\\n\n",
        "In machine learning, we deal with uncertainty using **probability theory**. A **probability distribution** describes how the values of a random variable are distributed. It tells us which values are more likely to occur.\\n\n",
        "\\n\n",
        "We distinguish between:\\n\n",
        "*   **Discrete Distributions** (e.g., Bernoulli, Binomial, Poisson). Defined by a Probability Mass Function (PMF).\\n\n",
        "*   **Continuous Distributions** (e.g., Gaussian, Beta, Gamma). Defined by a Probability Density Function (PDF).\\n\n",
        "\\n\n",
        "In this notebook, we focus on the most fundamental continuous distribution: the **Gaussian (Normal) Distribution**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. The Univariate Gaussian Distribution\\n\n",
        "\\n\n",
        "The Gaussian distribution $\\mathcal{N}(x | \\mu, \\sigma^2)$ is defined by two parameters:\\n\n",
        "1.  **Mean ($\\mu$)**: The center or expectation of the distribution.\\n\n",
        "2.  **Variance ($\\sigma^2$)**: The spread or width of the distribution. (Standard Deviation $\\sigma = \\sqrt{\\text{Variance}}$).\\n\n",
        "\\n\n",
        "### Formal Definition (PDF)\\n\n",
        "For a single variable $x$, the Probability Density Function is:\\n\n",
        "\\n\n",
        "$$ \\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp \\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right) $$\\n\n",
        "\\n\n",
        "*   The factor $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$ is a normalization constant ensuring the area under the curve sums to 1.\\n\n",
        "*   The quadratic term in the exponent $(x - \\mu)^2$ creates the bell shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (1591631810.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport numpy as np\\n\u001b[39m\n                       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\\n\n",
        "import matplotlib.pyplot as plt\\n\n",
        "from scipy.stats import norm\\n\n",
        "import seaborn as sns\\n\n",
        "\\n\n",
        "# Set plot style\\n\n",
        "sns.set_style(\"whitegrid\")\\n\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing the PDF and CDF\\n\n",
        "Let's visualize the Probability Density Function (PDF) and Cumulative Distribution Function (CDF) for a Standard Normal Distribution ($\\mu=0, \\sigma=1$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\\n\n",
        "mu = 0\\n\n",
        "sigma = 1\\n\n",
        "\\n\n",
        "# Define range for x\\n\n",
        "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\\n\n",
        "\\n\n",
        "# Calculate PDF and CDF\\n\n",
        "pdf_values = norm.pdf(x, loc=mu, scale=sigma)\\n\n",
        "cdf_values = norm.cdf(x, loc=mu, scale=sigma)\\n\n",
        "\\n\n",
        "# Plotting\\n\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\\n\n",
        "\\n\n",
        "# PDF Plot\\n\n",
        "ax[0].plot(x, pdf_values, label=f'$\\mu={mu}, \\sigma={sigma}$', color='blue', lw=2)\\n\n",
        "ax[0].fill_between(x, pdf_values, alpha=0.2, color='blue')\\n\n",
        "ax[0].set_title(\"Probability Density Function (PDF)\")\\n\n",
        "ax[0].set_xlabel(\"x\")\\n\n",
        "ax[0].set_ylabel(\"Probability Density\")\\n\n",
        "ax[0].legend()\\n\n",
        "\\n\n",
        "# CDF Plot\\n\n",
        "ax[1].plot(x, cdf_values, label=f'$\\mu={mu}, \\sigma={sigma}$', color='red', lw=2)\\n\n",
        "ax[1].set_title(\"Cumulative Distribution Function (CDF)\")\\n\n",
        "ax[1].set_xlabel(\"x\")\\n\n",
        "ax[1].set_ylabel(\"Cumulative Probability\")\\n\n",
        "ax[1].legend()\\n\n",
        "\\n\n",
        "plt.tight_layout()\\n\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sampling from a Gaussian\\n\n",
        "\\n\n",
        "In practice, we often don't know the true distribution but observe **samples** from it. As the number of samples increases, the empirical histogram converges to the theoretical PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate samples\\n\n",
        "num_samples = 1000\\n\n",
        "samples = np.random.normal(loc=mu, scale=sigma, size=num_samples)\\n\n",
        "\\n\n",
        "# Plot histogram vs theoretical PDF\\n\n",
        "plt.figure(figsize=(8, 5))\\n\n",
        "count, bins, ignored = plt.hist(samples, bins=30, density=True, alpha=0.6, color='g', label='Empirical Histogram')\\n\n",
        "plt.plot(x, pdf_values, linewidth=2, color='r', label='Theoretical PDF')\\n\n",
        "plt.title(f\"Sampling {num_samples} points from $\\mathcal{{N}}({mu}, {sigma}^2)$ \")\\n\n",
        "plt.legend()\\n\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. The Multivariate Gaussian (Optional but Important)\\n\n",
        "\\n\n",
        "For a $D$-dimensional vector $\\mathbf{x}$, the Gaussian distribution is defined by:\\n\n",
        "*   **Mean Vector ($\\boldsymbol{\\mu}$)**: A $D$-dimensional vector.\\n\n",
        "*   **Covariance Matrix ($\\boldsymbol{\\Sigma}$)**: A $D \\times D$ symmetric, positive-definite matrix describing spread and correlations.\\n\n",
        "\\n\n",
        "$$ \\mathcal{N}(\\mathbf{x} | \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{\\sqrt{(2\\pi)^D |\\boldsymbol{\\Sigma}|}} \\exp \\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}) \\right) $$\\n\n",
        "\\n\n",
        "Let's visualize a 2D Gaussian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import multivariate_normal\\n\n",
        "\\n\n",
        "# Parameters for 2D Gaussian\\n\n",
        "mu_2d = [0, 0]\\n\n",
        "cov_2d = [[1, 0.5], [0.5, 1]]  # Correlated variables\\n\n",
        "\\n\n",
        "# Create grid\\n\n",
        "x_grid, y_grid = np.mgrid[-3:3:.01, -3:3:.01]\\n\n",
        "pos = np.dstack((x_grid, y_grid))\\n\n",
        "\\n\n",
        "# Calculate PDF\\n\n",
        "rv = multivariate_normal(mu_2d, cov_2d)\\n\n",
        "z = rv.pdf(pos)\\n\n",
        "\\n\n",
        "# Plot Contour\\n\n",
        "plt.figure(figsize=(7, 6))\\n\n",
        "contour = plt.contourf(x_grid, y_grid, z, levels=20, cmap='viridis')\\n\n",
        "plt.colorbar(contour, label='Probability Density')\\n\n",
        "plt.title(\"2D Multivariate Gaussian Density\")\\n\n",
        "plt.xlabel(\"$x_1$\")\\n\n",
        "plt.ylabel(\"$x_2$\")\\n\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\\n\n",
        "\\n\n",
        "*   **Distributions** model uncertainty.\\n\n",
        "*   **PDF** describes the likelihood of continuous variables.\\n\n",
        "*   **Gaussian Distribution** is central to ML due to the Central Limit Theorem and its mathematical properties.\\n\n",
        "*   **Sampling** allows us to generate data that follows a specific distribution."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
